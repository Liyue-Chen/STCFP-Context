
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>tensorflow.python.keras.utils.tf_utils &#8212; UCTB  documentation</title>
    <link rel="stylesheet" href="../../../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../../../index.html">UCTB  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for tensorflow.python.keras.utils.tf_utils</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;TensorFlow-related utilities.&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">smart_cond</span> <span class="k">as</span> <span class="n">smart_module</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">sparse_tensor</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_shape</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_util</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">control_flow_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">variables</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">nest</span>


<span class="k">def</span> <span class="nf">smart_cond</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">true_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">false_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return either `true_fn()` if predicate `pred` is true else `false_fn()`.</span>

<span class="sd">  If `pred` is a bool or has a constant value, we return either `true_fn()`</span>
<span class="sd">  or `false_fn()`, otherwise we use `tf.cond` to dynamically route to both.</span>

<span class="sd">  Arguments:</span>
<span class="sd">    pred: A scalar determining whether to return the result of `true_fn` or</span>
<span class="sd">      `false_fn`.</span>
<span class="sd">    true_fn: The callable to be performed if pred is true.</span>
<span class="sd">    false_fn: The callable to be performed if pred is false.</span>
<span class="sd">    name: Optional name prefix when using `tf.cond`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Tensors returned by the call to either `true_fn` or `false_fn`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: If `true_fn` or `false_fn` is not callable.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">variables</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
        <span class="n">pred</span><span class="p">,</span> <span class="n">true_fn</span><span class="o">=</span><span class="n">true_fn</span><span class="p">,</span> <span class="n">false_fn</span><span class="o">=</span><span class="n">false_fn</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">smart_module</span><span class="o">.</span><span class="n">smart_cond</span><span class="p">(</span>
      <span class="n">pred</span><span class="p">,</span> <span class="n">true_fn</span><span class="o">=</span><span class="n">true_fn</span><span class="p">,</span> <span class="n">false_fn</span><span class="o">=</span><span class="n">false_fn</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">constant_value</span><span class="p">(</span><span class="n">pred</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return the bool value for `pred`, or None if `pred` had a dynamic value.</span>

<span class="sd">  Arguments:</span>
<span class="sd">    pred: A scalar, either a Python bool or a TensorFlow boolean variable</span>
<span class="sd">      or tensor, or the Python integer 1 or 0.</span>

<span class="sd">  Returns:</span>
<span class="sd">    True or False if `pred` has a constant boolean value, None otherwise.</span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: If `pred` is not a Variable, Tensor or bool, or Python</span>
<span class="sd">      integer 1 or 0.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Allow integer booleans.</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">pred</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">pred</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">variables</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
    <span class="k">return</span> <span class="kc">None</span>
  <span class="k">return</span> <span class="n">smart_module</span><span class="o">.</span><span class="n">smart_constant_value</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">is_tensor_or_tensor_list</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
  <span class="n">v</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">v</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="kc">True</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span> <span class="nf">get_reachable_from_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the set of tensors/ops reachable from `inputs`.</span>

<span class="sd">  Stops if all targets have been found (target is optional).</span>

<span class="sd">  Only valid in Symbolic mode, not Eager mode.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: List of tensors.</span>
<span class="sd">    targets: List of tensors.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A set of tensors reachable from the inputs (includes the inputs themselves).</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">reachable</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">targets</span><span class="p">:</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
  <span class="n">queue</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:]</span>

  <span class="k">while</span> <span class="n">queue</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Operation</span><span class="p">):</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">outputs</span><span class="p">[:]</span> <span class="ow">or</span> <span class="p">[]</span>
      <span class="n">outputs</span> <span class="o">+=</span> <span class="n">x</span><span class="o">.</span><span class="n">_control_outputs</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">variables</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">consumers</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Expected Operation, Variable, or Tensor, got &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">reachable</span><span class="p">:</span>
        <span class="n">reachable</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">queue</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">targets</span> <span class="ow">and</span> <span class="n">targets</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">reachable</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">reachable</span>
  <span class="k">return</span> <span class="n">reachable</span>


<span class="k">def</span> <span class="nf">shape_type_conversion</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Decorator that handles tuple/TensorShape conversion.</span>

<span class="sd">  Used in `compute_output_shape` and `build`.</span>

<span class="sd">  Arguments:</span>
<span class="sd">    fn: function to wrap.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Wrapped function.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">[</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_shape</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
    <span class="n">output_shape</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_shape</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">wrapper</span>


<span class="k">def</span> <span class="nf">are_all_symbolic_tensors</span><span class="p">(</span><span class="n">tensors</span><span class="p">):</span>
  <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">is_symbolic_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">)</span>


<span class="n">_user_convertible_tensor_types</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">is_symbolic_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns whether a tensor is symbolic (from a TF graph) or an eager tensor.</span>

<span class="sd">  A Variable can be seen as either: it is considered symbolic</span>
<span class="sd">  when we are in a graph scope, and eager when we are in an eager scope.</span>

<span class="sd">  Arguments:</span>
<span class="sd">    tensor: A tensor instance to test.</span>

<span class="sd">  Returns:</span>
<span class="sd">    True for symbolic tensors, False for eager tensors.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">variables</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
    <span class="k">return</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">()</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sparse_tensor</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">)):</span>
    <span class="k">return</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="s1">&#39;graph&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_user_convertible_tensor_types</span><span class="p">)):</span>
    <span class="k">return</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">),</span> <span class="s1">&#39;graph&#39;</span><span class="p">)</span>
  <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span> <span class="nf">register_symbolic_tensor_type</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Allows users to specify types regarded as symbolic `Tensor`s.</span>

<span class="sd">  Used in conjunction with `tf.register_tensor_conversion_function`, calling</span>
<span class="sd">  `tf.keras.utils.register_symbolic_tensor_type(cls)` allows non-`Tensor`</span>
<span class="sd">  objects to be plumbed through Keras layers.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  # One-time setup.</span>
<span class="sd">  class Foo(object):</span>
<span class="sd">    def __init__(self, input_):</span>
<span class="sd">      self._input = input_</span>
<span class="sd">    def value(self):</span>
<span class="sd">      return tf.constant(42.)</span>

<span class="sd">  tf.register_tensor_conversion_function(</span>
<span class="sd">      Foo, lambda x, *args, **kwargs: x.value())</span>

<span class="sd">  tf.keras.utils.register_symbolic_tensor_type(Foo)</span>

<span class="sd">  # User-land.</span>
<span class="sd">  layer = tf.keras.layers.Lambda(lambda input_: Foo(input_))</span>
<span class="sd">  ```</span>

<span class="sd">  Arguments:</span>
<span class="sd">    cls: A `class` type which shall be regarded as a symbolic `Tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">global</span> <span class="n">_user_convertible_tensor_types</span>
  <span class="n">_user_convertible_tensor_types</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../../../index.html">UCTB  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, Di Chai, Leye Wang, Jin Xu, Wenjie Yang, Liyue Chen.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.2.1.
    </div>
  </body>
</html>